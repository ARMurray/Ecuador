V4$DateTime <- as.character(V4$DateTime)
V4$DateTime <- as.POSIXct(substr(V4$DateTime,1,16))
V4 <- V4[complete.cases(V4),]
vMerge <- merge(V1,V2)
vMerge <- merge(vMerge,V3)
vMerge <- merge(vMerge,V4)
# C6 Data
C6 <- read.csv(here("data_4_analysis/C6.csv"))%>%
select(DateTime,Turbidity_NTU,Chlorophylla_ug.L,Phycocyanin_ppb,CDOM_ppb)
C6$DateTime <- as.POSIXct(C6$DateTime, format = "%m/%d/%Y %H:%M")
# eosFD Data
eosFD <- read.csv(here("data_4_analysis/eosFD_All.csv"))%>%
select(-X)
eosFD$DateTime <- as.POSIXct(eosFD$DateTime)
# Precipitation Data
ppt <- read.csv(here("data_4_analysis/ppt_5min.csv"))
ppt$DateTime <- as.POSIXct(as.character(ppt$DateTime), format = "%m/%d/%Y %H:%M")
# Air Temperature Data
air <- read.csv(here("data_4_analysis/airTemp_5min.csv"))
air$DateTime <- as.POSIXct(as.character(air$DateTime), format = "%m/%d/%Y %H:%M")
# Level Data
lvl <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, LEVEL_m,Serial)%>%
spread(Serial,LEVEL_m)
colnames(lvl) <- c("DateTime","lvl_421_m","lvl_425_m","lvl_430_m","lvl_435_m",
"lvl_436_m","lvl_437_m","lvl_442_m")
lvl$DateTime <- as.POSIXct(as.character(lvl$DateTime))
# Water Temperature Data
watTemp <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, TEMP_c,Serial)%>%
spread(Serial,TEMP_c)
colnames(watTemp) <- c("DateTime","tempC_421_m","tempC_425_m","tempC_430_m",
"tempC_435_m","tempC_436_m","tempC_437_m","tempC_442_m")
watTemp$DateTime <- as.POSIXct(as.character(watTemp$DateTime))
# Merge
merge <- merge(vMerge,C6, all = TRUE)
merge <- merge(merge, eosFD, all = TRUE)%>%
distinct()
merge <- merge(merge,ppt, all = TRUE)
merge <- merge(merge,lvl, all = TRUE)
merge <- merge(merge,watTemp, all = TRUE)
merge <- merge(merge, air, all = TRUE)
# STILL NEED DO EC AND LEVEL
## Create new precipitation variables
ppt24Df <- data.frame()
for(n in 2449:nrow(merge)){
date <- as.POSIXct(as.character(merge[n,'DateTime']))
sub <- merge%>%
filter(DateTime < date & DateTime > date - 86400) #86,400 is the number of seconds in a day
pptTot <- sum(sub$ppt_mm, na.rm = TRUE)
newData <- data.frame("DateTime" = date, "ppt24Tot" = pptTot)
ppt24Df <- rbind(ppt24Df, newData)
}
ppt48Df <- data.frame()
for(n in 2449:nrow(merge)){
date <- as.POSIXct(as.character(merge[n,'DateTime']))
sub <- merge%>%
filter(DateTime < date & DateTime > date - 172800) #86,400 is the number of seconds in a day
pptTot <- sum(sub$ppt_mm, na.rm = TRUE)
newData <- data.frame("DateTime" = date, "ppt48Tot" = pptTot)
ppt48Df <- rbind(ppt48Df, newData)
}
ppt72Df <- data.frame()
for(n in 2449:nrow(merge)){
date <- as.POSIXct(as.character(merge[n,'DateTime']))
sub <- merge%>%
filter(DateTime < date & DateTime > date - 259200) #86,400 is the number of seconds in a day
pptTot <- sum(sub$ppt_mm, na.rm = TRUE)
newData <- data.frame("DateTime" = date, "ppt72Tot" = pptTot)
ppt72Df <- rbind(ppt72Df, newData)
}
df <- merge(merge,ppt24Df, all = TRUE)
df <- merge(df,ppt48Df, all = TRUE)
df <- merge(df,ppt72Df, all = TRUE)
# We don't want to go too crazy with interpolating data we did not collect
# HOWEVER, there is some data we can do this for, such as water level since we collected it consistently
# and we are interpolating very short periods of time for the purpose of having values in every row
# to go along with the other variables such as pCO2
# linear estimation of water level
df$lvl_421_m <- na.approx(df$lvl_421_m)
# linear estimation of water level
try <- na.approx(df$lvl_421_m)
try
# Merge all data into a single dataframe
library(here)
library(tidyr)
library(dplyr)
library(zoo)
# Vaisala Data
Vaisala <- read.csv(here("data_4_analysis/Vaisala_Stations_AllData.csv"))
Vaisala$DateTime <- as.POSIXct(Vaisala$DateTime)
Vaisala <- Vaisala%>%
mutate(ID = paste0(Vaisala$DateTime,Vaisala$VID))
# Remove Duplicates
Vaisala <- Vaisala[!duplicated(Vaisala[,'ID']),]%>%
select(-X, -ID)%>%
spread(VID,PPM)
View(Vaisala)
# Need to get rid of the seconds in Vaisala times because they are staggering data
V1 <- Vaisala%>%
select(DateTime,V1)
V1$DateTime <- as.character(V1$DateTime)
V1$DateTime <- as.POSIXct(substr(V1$DateTime,1,16))
V1 <- V1[complete.cases(V1),]
V2 <- Vaisala%>%
select(DateTime,V2)
V2$DateTime <- as.character(V2$DateTime)
V2$DateTime <- as.POSIXct(substr(V2$DateTime,1,16))
V2 <- V2[complete.cases(V2),]
V3 <- Vaisala%>%
select(DateTime,V3)
V3$DateTime <- as.character(V3$DateTime)
V3$DateTime <- as.POSIXct(substr(V3$DateTime,1,16))
V3 <- V3[complete.cases(V3),]
V4 <- Vaisala%>%
select(DateTime,V4)
V4$DateTime <- as.character(V4$DateTime)
V4$DateTime <- as.POSIXct(substr(V4$DateTime,1,16))
V4 <- V4[complete.cases(V4),]
vMerge <- merge(V1,V2)
vMerge <- merge(vMerge,V3)
vMerge <- merge(vMerge,V4)
View(vMerge)
# C6 Data
C6 <- read.csv(here("data_4_analysis/C6.csv"))%>%
select(DateTime,Turbidity_NTU,Chlorophylla_ug.L,Phycocyanin_ppb,CDOM_ppb)
C6$DateTime <- as.POSIXct(C6$DateTime, format = "%m/%d/%Y %H:%M")
# eosFD Data
eosFD <- read.csv(here("data_4_analysis/eosFD_All.csv"))%>%
select(-X)
eosFD$DateTime <- as.POSIXct(eosFD$DateTime)
# Precipitation Data
ppt <- read.csv(here("data_4_analysis/ppt_5min.csv"))
ppt$DateTime <- as.POSIXct(as.character(ppt$DateTime), format = "%m/%d/%Y %H:%M")
View(ppt)
# Air Temperature Data
air <- read.csv(here("data_4_analysis/airTemp_5min.csv"))
air$DateTime <- as.POSIXct(as.character(air$DateTime), format = "%m/%d/%Y %H:%M")
# Level Data
lvl <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, LEVEL_m,Serial)%>%
spread(Serial,LEVEL_m)
colnames(lvl) <- c("DateTime","lvl_421_m","lvl_425_m","lvl_430_m","lvl_435_m",
"lvl_436_m","lvl_437_m","lvl_442_m")
lvl$DateTime <- as.POSIXct(as.character(lvl$DateTime))
# Water Temperature Data
watTemp <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, TEMP_c,Serial)%>%
spread(Serial,TEMP_c)
colnames(watTemp) <- c("DateTime","tempC_421_m","tempC_425_m","tempC_430_m",
"tempC_435_m","tempC_436_m","tempC_437_m","tempC_442_m")
watTemp$DateTime <- as.POSIXct(as.character(watTemp$DateTime))
# Merge
merge <- merge(vMerge,C6, all = TRUE)
merge <- merge(merge, eosFD, all = TRUE)%>%
distinct()
merge <- merge(merge,ppt, all = TRUE)
merge <- merge(merge,lvl, all = TRUE)
merge <- merge(merge,watTemp, all = TRUE)
merge <- merge(merge, air, all = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(tidyverse)
library(here)
library(plotly)
level <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))
level$DateTime <- as.POSIXct(as.character(level$DateTime),format = "%Y-%m-%d %H:%M")
df <- read.csv(here("data_4_analysis/All_Stream_Data.csv"))
level$Serial <- as.factor(level$Serial)
ggplot(level)+
geom_point(aes(x=DateTime, y = LEVEL_m, group = Serial, col = Serial))+
labs(x = "Date", y = "Level (m)")
stn1_2 <- level%>%
filter(Serial == "2020436" | Serial == "2020421")%>%
select(DateTime, LEVEL_m, Serial)
stn1_2_wide <- spread(stn1_2, Serial, LEVEL_m)
colnames(stn1_2_wide) <- c("DateTime","Station_3","Station_1")
stn1_2_complete <- na.omit(stn1_2_wide) # Keep only rows with both data points
lm <- lm(stn1_2_complete$Station_1~stn1_2_complete$Station_3)
summary(lm)
lvl4est <- stn1_2_wide%>%
filter(is.na(Station_1) & !is.na(Station_3))
lvl4est$Station_1 <- lvl4est$Station_3 - (lvl4est$Station_3 * 0.047655)
levelMod <- stn1_2_wide%>%
filter(!is.na(Station_1))
levelMod <- rbind(levelMod,lvl4est)
p <- ggplot(levelMod)+
geom_point(aes(x = DateTime, y = Station_1), col="orange")+
geom_point(aes(x = DateTime, y = Station_3), col="#20bab2")
ggplotly(p)
discharge <- read.csv(here("data_4_analysis/recorded_discharge.csv"))
discharge$DateTime <-as.POSIXct(paste0(discharge$Date,"",discharge$Time),format = "%m/%d/%Y %H:%M")
discharge <- discharge%>%
select(DateTime,Stn,Level,Discharge)
ggplot(discharge)+
geom_point(aes(x = Discharge, y = Level, col = Stn), size = 3)
ggplotly(p)
# Merge all data into a single dataframe
library(here)
library(tidyr)
library(dplyr)
library(zoo)
# Vaisala Data
Vaisala <- read.csv(here("data_4_analysis/Vaisala_Stations_AllData.csv"))
Vaisala$DateTime <- as.POSIXct(Vaisala$DateTime)
Vaisala <- Vaisala%>%
mutate(ID = paste0(Vaisala$DateTime,Vaisala$VID))
# Remove Duplicates
Vaisala <- Vaisala[!duplicated(Vaisala[,'ID']),]%>%
select(-X, -ID)%>%
spread(VID,PPM)
# Need to get rid of the seconds in Vaisala times because they are staggering data
V1 <- Vaisala%>%
select(DateTime,V1)
V1$DateTime <- as.character(V1$DateTime)
V1$DateTime <- as.POSIXct(substr(V1$DateTime,1,16))
V1 <- V1[complete.cases(V1),]
V2 <- Vaisala%>%
select(DateTime,V2)
V2$DateTime <- as.character(V2$DateTime)
V2$DateTime <- as.POSIXct(substr(V2$DateTime,1,16))
V2 <- V2[complete.cases(V2),]
V3 <- Vaisala%>%
select(DateTime,V3)
V3$DateTime <- as.character(V3$DateTime)
V3$DateTime <- as.POSIXct(substr(V3$DateTime,1,16))
V3 <- V3[complete.cases(V3),]
V4 <- Vaisala%>%
select(DateTime,V4)
V4$DateTime <- as.character(V4$DateTime)
V4$DateTime <- as.POSIXct(substr(V4$DateTime,1,16))
V4 <- V4[complete.cases(V4),]
vMerge <- merge(V1,V2)
vMerge <- merge(vMerge,V3)
vMerge <- merge(vMerge,V4)
# C6 Data
C6 <- read.csv(here("data_4_analysis/C6.csv"))%>%
select(DateTime,Turbidity_NTU,Chlorophylla_ug.L,Phycocyanin_ppb,CDOM_ppb)
C6$DateTime <- as.POSIXct(C6$DateTime, format = "%m/%d/%Y %H:%M")
# eosFD Data
eosFD <- read.csv(here("data_4_analysis/eosFD_All.csv"))%>%
select(-X)
eosFD$DateTime <- as.POSIXct(eosFD$DateTime)
# Precipitation Data
ppt <- read.csv(here("data_4_analysis/ppt_5min.csv"))
ppt$DateTime <- as.POSIXct(as.character(ppt$DateTime), format = "%m/%d/%Y %H:%M")
# Air Temperature Data
air <- read.csv(here("data_4_analysis/airTemp_5min.csv"))
air$DateTime <- as.POSIXct(as.character(air$DateTime), format = "%m/%d/%Y %H:%M")
# Level Data
lvl <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, LEVEL_m,Serial)%>%
spread(Serial,LEVEL_m)
colnames(lvl) <- c("DateTime","lvl_421_m","lvl_425_m","lvl_430_m","lvl_435_m",
"lvl_436_m","lvl_437_m","lvl_442_m")
lvl$DateTime <- as.POSIXct(as.character(lvl$DateTime))
View(lvl)
library(ggplot2)
library(tidyverse)
library(here)
library(plotly)
level <- read.csv(here("FieldData/LevelLogger/WaterLevel_All.csv"))
level$DateTime <- as.POSIXct(as.character(level$DateTime),format = "%Y-%m-%d %H:%M")
# Clean errors from Level data
level <- level%>%
filter(LEVEL_m > .08) # These are the times loggers were out of the water
# Vaisala Data
Vaisala <- read.csv(here("data_4_analysis/Vaisala_Stations_AllData.csv"))
Vaisala$DateTime <- as.POSIXct(Vaisala$DateTime)
Vaisala <- Vaisala%>%
mutate(ID = paste0(Vaisala$DateTime,Vaisala$VID))
# Remove Duplicates
Vaisala <- Vaisala[!duplicated(Vaisala[,'ID']),]%>%
select(-X, -ID)%>%
spread(VID,PPM)
# Need to get rid of the seconds in Vaisala times because they are staggering data
V1 <- Vaisala%>%
select(DateTime,V1)
V1$DateTime <- as.character(V1$DateTime)
V1$DateTime <- as.POSIXct(substr(V1$DateTime,1,16))
V1 <- V1[complete.cases(V1),]
V2 <- Vaisala%>%
select(DateTime,V2)
V2$DateTime <- as.character(V2$DateTime)
V2$DateTime <- as.POSIXct(substr(V2$DateTime,1,16))
V2 <- V2[complete.cases(V2),]
V3 <- Vaisala%>%
select(DateTime,V3)
V3$DateTime <- as.character(V3$DateTime)
V3$DateTime <- as.POSIXct(substr(V3$DateTime,1,16))
V3 <- V3[complete.cases(V3),]
V4 <- Vaisala%>%
select(DateTime,V4)
V4$DateTime <- as.character(V4$DateTime)
V4$DateTime <- as.POSIXct(substr(V4$DateTime,1,16))
V4 <- V4[complete.cases(V4),]
vMerge <- merge(V1,V2)
vMerge <- merge(vMerge,V3)
vMerge <- merge(vMerge,V4)
# C6 Data
C6 <- read.csv(here("data_4_analysis/C6.csv"))%>%
select(DateTime,Turbidity_NTU,Chlorophylla_ug.L,Phycocyanin_ppb,CDOM_ppb)
C6$DateTime <- as.POSIXct(C6$DateTime, format = "%m/%d/%Y %H:%M")
# eosFD Data
eosFD <- read.csv(here("data_4_analysis/eosFD_All.csv"))%>%
select(-X)
eosFD$DateTime <- as.POSIXct(eosFD$DateTime)
# Precipitation Data
ppt <- read.csv(here("data_4_analysis/ppt_5min.csv"))
ppt$DateTime <- as.POSIXct(as.character(ppt$DateTime), format = "%m/%d/%Y %H:%M")
# Air Temperature Data
air <- read.csv(here("data_4_analysis/airTemp_5min.csv"))
air$DateTime <- as.POSIXct(as.character(air$DateTime), format = "%m/%d/%Y %H:%M")
# Level Data
lvl <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, LEVEL_m,Serial)%>%
spread(Serial,LEVEL_m)
colnames(lvl) <- c("DateTime","lvl_421_m","lvl_425_m","lvl_430_m","lvl_435_m",
"lvl_436_m","lvl_437_m","lvl_442_m")
lvl$DateTime <- as.POSIXct(as.character(lvl$DateTime))
# Water Temperature Data
watTemp <- read.csv(here("data_4_analysis/WaterLevel_Cleaned.csv"))%>%
select(DateTime, TEMP_c,Serial)%>%
spread(Serial,TEMP_c)
colnames(watTemp) <- c("DateTime","tempC_421_m","tempC_425_m","tempC_430_m",
"tempC_435_m","tempC_436_m","tempC_437_m","tempC_442_m")
watTemp$DateTime <- as.POSIXct(as.character(watTemp$DateTime))
# Merge
merge <- merge(vMerge,C6, all = TRUE)
merge <- merge(merge, eosFD, all = TRUE)%>%
distinct()
merge <- merge(merge,ppt, all = TRUE)
merge <- merge(merge,lvl, all = TRUE)
merge <- merge(merge,watTemp, all = TRUE)
merge <- merge(merge, air, all = TRUE)
# linear estimation of water level
try <- na.approx(df$lvl_421_m)
### Get a list of all the DO1 files
DO1_Files <- list.files(here::here("FieldData/DO"),pattern = 'DO_1')
### Get a list of all the DO1 files
DO1_Files <- list.files(here::here("FieldData/DO"),pattern = 'DO_1',recursive = TRUE)
### Create an empty data frame
allDO1Data <- data.frame()
### Combine all DO1 data
for(i in 1:length(DO1_Files)){
file <- DO1_Files[i]
data <- read.csv(here::here("FieldData/DO",file),skip = 2,
blank.lines.skip = TRUE, header = FALSE)
data <- data[,2:4]
colnames(data) <- c("DateTime","DO_mg_L","Temp_C")
allDO1Data <- rbind(allDO1Data,data)
}
View(data)
### Get a list of all the DO1 files
DO1_Files <- list.files(here::here("FieldData/DO/Last_Collection"),pattern = 'DO_1')
### Create an empty data frame
allDO1Data <- data.frame()
### Combine all DO1 data
for(i in 1:length(DO1_Files)){
file <- DO1_Files[i]
data <- read.csv(here::here("FieldData/DO",file),skip = 2,
blank.lines.skip = TRUE, header = FALSE)
data <- data[,2:4]
colnames(data) <- c("DateTime","DO_mg_L","Temp_C")
allDO1Data <- rbind(allDO1Data,data)
}
### Get a list of all the DO1 files
DO1_Files <- list.files(here::here("FieldData/DO/Last_Collection"),pattern = 'DO_1')
### Create an empty data frame
allDO1Data <- data.frame()
### Combine all DO1 data
for(i in 1:length(DO1_Files)){
file <- DO1_Files[i]
data <- read.csv(here::here("FieldData/DO",file),skip = 2,
blank.lines.skip = TRUE, header = FALSE)
data <- data[,2:4]
colnames(data) <- c("DateTime","DO_mg_L","Temp_C")
allDO1Data <- rbind(allDO1Data,data)
}
DO1_Files
DO1_Data <- here("FieldData/DO/Last_Collection/DO_1_2019-08-14.csv")
DO1_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_1_2019-08-14.csv"))
DO1_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_1_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
View(DO1_Data)
DO1_Data <- DO1_Data[,2:4]
colnames(DO1_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO1_Data$DateTime <- as.POSIXct(as.character(allDO1Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
### Convert time from factor to POSIXct
DO1_Data$DateTime <- as.POSIXct(as.character(DO1_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO1_Data <- DO1_Data[complete.cases(DO1_Data), ]%>%
mutate(Station = "1")
## DO Sensor #2
DO2_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_2_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
DO2_Data <- DO2_Data[,2:4]
colnames(DO2_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO2_Data$DateTime <- as.POSIXct(as.character(DO2_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO2_Data <- DO2_Data[complete.cases(DO2_Data), ]%>%
mutate(Station = "2")
View(DO2_Data)
## DO Sensor #3
DO3_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_3_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
DO3_Data <- DO3_Data[,2:4]
colnames(DO3_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO3_Data$DateTime <- as.POSIXct(as.character(DO3_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO3_Data <- DO3_Data[complete.cases(DO3_Data), ]%>%
mutate(Station = "3")
allDOdata <- rbind(DO1_Data,DO2_Data,DO3_Data)
temp_C <- data.frame()
for(n in 1:nrow(allDOdata)){
row <- allDOdata[n,]
if (row$Temp_C > 25){
temp <- (row$Temp_C - 32)*(5/9)
} else{
temp <- row$Temp_C
}
temp_C <- rbind(temp_C,temp)
}
View(temp_C)
allDOdata$Temp_C <- temp_C$X12.0222222222222
write.csv(allDOdata, here("data_4_analysis/DO.csv"))
View(allDOdata)
# Dissolved Oxygen data processing
library(here)
library(dplyr)
library(ggplot2)
## DO Sensor #1
DO1_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_1_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
DO1_Data <- DO1_Data[,2:4]
colnames(DO1_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO1_Data$DateTime <- as.POSIXct(as.character(DO1_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO1_Data <- DO1_Data[complete.cases(DO1_Data), ]%>%
mutate(Station = "1")
## DO Sensor #2
DO2_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_2_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
DO2_Data <- DO2_Data[,2:4]
colnames(DO2_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO2_Data$DateTime <- as.POSIXct(as.character(DO2_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO2_Data <- DO2_Data[complete.cases(DO2_Data), ]%>%
mutate(Station = "2")
## DO Sensor #3
DO3_Data <- read.csv(here("FieldData/DO/Last_Collection/DO_3_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
DO3_Data <- DO3_Data[,2:4]
colnames(DO3_Data) <- c("DateTime","DO_mg_L","Temp_C")
### Convert time from factor to POSIXct
DO3_Data$DateTime <- as.POSIXct(as.character(DO3_Data$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
DO3_Data <- DO3_Data[complete.cases(DO3_Data), ]%>%
mutate(Station = "4")
### Combine all data
allDOdata <- rbind(DO1_Data,DO2_Data,DO3_Data)
temp_C <- data.frame()
for(n in 1:nrow(allDOdata)){
row <- allDOdata[n,]
if (row$Temp_C > 25){
temp <- (row$Temp_C - 32)*(5/9)
} else{
temp <- row$Temp_C
}
temp_C <- rbind(temp_C,temp)
}
allDOdata$Temp_C <- temp_C$X12.0222222222222
write.csv(allDOdata, here("data_4_analysis/DO.csv"))
EC1 <- read.csv(here("FieldData/EC/Last_Collection/EC1_2019-08-14.csv"))
EC1 <- read.csv(here("FieldData/EC/Last_Collection/EC1_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
View(EC1)
EC1 <- EC1[,2:4]
colnames(EC1) <- c("DateTime","uS","Temp_C")
### Convert time from factor to POSIXct
EC1$DateTime <- as.POSIXct(as.character(EC1$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
EC1 <- EC1[complete.cases(EC1), ]%>%
mutate(Station = "1")
EC2 <- read.csv(here("FieldData/EC/Last_Collection/EC2_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
EC2 <- EC2[,2:4]
colnames(EC2) <- c("DateTime","uS","Temp_C")
EC2$DateTime <- as.POSIXct(as.character(EC2$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
EC2 <- EC2[complete.cases(EC2), ]%>%
mutate(Station = "2")
# Station 4
EC3 <- read.csv(here("FieldData/EC/Last_Collection/EC3_2019-08-14.csv"),
skip = 2, blank.lines.skip = TRUE, header = FALSE)
EC3 <- EC3[,2:4]
colnames(EC3) <- c("DateTime","uS","Temp_C")
EC3$DateTime <- as.POSIXct(as.character(EC3$DateTime),
format = '%m/%d/%y %I:%M:%OS %p')
EC3 <- EC3[complete.cases(EC3), ]%>%
mutate(Station = "4")
allEC <- rbind(EC1,EC2,EC3)
allEC$Temp_C <- allEC$Temp_C - 32*(5/9)
View(allEC)
write.csv(allEC, here("data_4_analysis/all_EC.csv"))
write.csv(allDOdata, here("data_4_analysis/all_DO.csv"))
